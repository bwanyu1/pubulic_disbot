import discord
import fitz  # PyMuPDF for PDF
from pptx import Presentation
from docx import Document
from dotenv import load_dotenv
from groq import Groq
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
EMBED_MODEL = os.getenv("EMBED_MODEL", "Qwen/qwen3-embedding-8b")
RERANK_MODEL = os.getenv("RERANK_MODEL", "Qwen/qwen3-4b-rerank")
PDF_CHUNK_SIZE = int(os.getenv("PDF_CHUNK_SIZE", 20))
PPTX_CHUNK_SIZE = int(os.getenv("PPTX_CHUNK_SIZE", 20))
TEXT_CHUNK_SIZE = int(os.getenv("TEXT_CHUNK_SIZE", 3000))
TOP_K = int(os.getenv("RAG_TOP_K", 5))

# ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆæœŸåŒ–
Groclient = Groq(api_key=GROQ_API_KEY)
embed_model = SentenceTransformer(EMBED_MODEL)
embed_dim = embed_model.get_sentence_embedding_dimension()
index = faiss.IndexFlatL2(embed_dim)
# FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
metadata = []  # list of dict: {"thread_id": int, "text": str}

# Discordè¨­å®š
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)
tree = discord.app_commands.CommandTree(client)

# --- ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡º & ãƒãƒ£ãƒ³ã‚¯åŒ–é–¢æ•° ---
def extract_and_chunk_pdf(file_bytes):
    chunks = []
    with fitz.open(stream=file_bytes, filetype="pdf") as doc:
        pages = [page.get_text() for page in doc]
        for i in range(0, len(pages), PDF_CHUNK_SIZE):
            chunks.append("\n".join(pages[i:i+PDF_CHUNK_SIZE]))
    return chunks


def extract_and_chunk_pptx(file_bytes):
    chunks = []
    tmp = "temp.pptx"
    with open(tmp, "wb") as f:
        f.write(file_bytes)
    prs = Presentation(tmp)
    os.remove(tmp)
    slides = []
    for slide in prs.slides:
        text = ""
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text += shape.text + "\n"
        slides.append(text)
    for i in range(0, len(slides), PPTX_CHUNK_SIZE):
        chunks.append("\n".join(slides[i:i+PPTX_CHUNK_SIZE]))
    return chunks


def extract_and_chunk_docx(file_bytes):
    tmp = "temp.docx"
    with open(tmp, "wb") as f:
        f.write(file_bytes)
    doc = Document(tmp)
    os.remove(tmp)
    paras = [p.text for p in doc.paragraphs]
    text = "\n".join(paras)
    return [text[i:i+TEXT_CHUNK_SIZE] for i in range(0, len(text), TEXT_CHUNK_SIZE)]

def rerank_chunks(chunks):
    # Rerankç”¨ã®åŸ‹ã‚è¾¼ã¿è¨ˆç®—
    rerank_embeddings = embed_model.encode(chunks, convert_to_numpy=True)
    rerank_index = faiss.IndexFlatL2(embed_dim)
    rerank_index.add(rerank_embeddings.astype('float32'))
    
    # Rerankå‡¦ç†
    D, I = rerank_index.search(rerank_embeddings.astype('float32'), TOP_K)
    return [chunks[i] for i in I[0]]
def extract_and_chunk_txt(file_bytes):
    text = file_bytes.decode("utf-8")
    return [text[i:i+TEXT_CHUNK_SIZE] for i in range(0, len(text), TEXT_CHUNK_SIZE)]

# --- è¦ç´„ & FAISSç™»éŒ² ---
async def process_and_store(chunks, thread_id):
    # åŸ‹ã‚è¾¼ã¿è¨ˆç®—
    embeddings = embed_model.encode(chunks, convert_to_numpy=True)
    # FAISSã¨metadataã«è¿½åŠ 
    index.add(embeddings.astype('float32'))
    for text in chunks:
        metadata.append({"thread_id": thread_id, "text": text})

    # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«è¦ç´„
    summaries = []
    for idx, chunk in enumerate(chunks):
        prompt = (
            f"ã€ãƒãƒ£ãƒ³ã‚¯ {idx+1}/{len(chunks)}ã€‘\n"
            "ä»¥ä¸‹ã®æ–‡ç« ã‚’è¦ç´„ã—ã€æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚è‹±èªãªã‚‰æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„:\n\n" + chunk
        )
        resp = Groclient.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile",
        )
        summary = resp.choices[0].message.content.strip()
        summaries.append(summary)
        channel = client.get_channel(thread_id)
        await channel.send(f"**ãƒãƒ£ãƒ³ã‚¯ {idx+1} è¦ç´„**:\n{summary}")

    # ç·åˆè¦ç´„
    combined = "\n\n".join([f"ãƒãƒ£ãƒ³ã‚¯ {i+1}: {s}" for i, s in enumerate(summaries)])
    overall_prompt = (
        "ä»¥ä¸‹ã¯è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯è¦ç´„ã§ã™ã€‚ã“ã‚Œã‚‰ã‚’å‚è€ƒã«å…¨ä½“ã®ç·åˆè¦ç´„ã‚’ä½œæˆã—ã€æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚:\n\n"
        + combined
    )
    overall_resp = Groclient.chat.completions.create(
        messages=[{"role": "user", "content": overall_prompt}],
        model="llama-3.3-70b-versatile",
    )
    overall = overall_resp.choices[0].message.content.strip()
    channel = client.get_channel(thread_id)
    await channel.send(f"**ğŸ’¡ ç·åˆè¦ç´„**:\n{overall}")

# --- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡ ---
@client.event
async def on_message(message):
    if message.author.bot:
        return

    # æ·»ä»˜ or ãƒ†ã‚­ã‚¹ãƒˆ
    if message.attachments or message.content:
        # ã‚¹ãƒ¬ãƒƒãƒ‰ä½œæˆ or å–å¾—
        if not isinstance(message.channel, discord.Thread):
            thread = await message.create_thread(name="è¦ç´„ãƒ»ç¿»è¨³çµæœ")
        else:
            thread = message.channel

        # ãƒ†ã‚­ã‚¹ãƒˆå˜ä½“
        if message.content and not message.attachments:
            chunks = [message.content]
        else:
            att = message.attachments[0]
            data = await att.read()
            name = att.filename.lower()
            if name.endswith('.pdf'):
                chunks = extract_and_chunk_pdf(data)
            elif name.endswith('.pptx'):
                chunks = extract_and_chunk_pptx(data)
            elif name.endswith('.docx'):
                chunks = extract_and_chunk_docx(data)
            elif name.endswith('.txt'):
                chunks = extract_and_chunk_txt(data)
            else:
                await thread.send("å¯¾å¿œã—ã¦ã„ã‚‹å½¢å¼ã¯ .txt, .pdf, .docx, .pptx ã§ã™ã€‚")
                return

        # å‡¦ç† & ä¿å­˜
        await process_and_store(chunks, thread.id)

# --- ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã‚³ãƒãƒ³ãƒ‰: RAG QA ---
@tree.command(name="qa", description="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰å›ç­”ã‚’å–å¾—ã—ã¾ã™ã€‚")
async def rag_qa(interaction: discord.Interaction, question: str):
    await interaction.response.defer()
    # è³ªå•ã‚’åŸ‹ã‚è¾¼ã¿
    q_vec = embed_model.encode([question], convert_to_numpy=True).astype('float32')
    D, I = index.search(q_vec, TOP_K)
    # ä¸Šä½ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—
    contexts = []
    for idx in I[0]:
        if idx < len(metadata):
            contexts.append(metadata[idx]['text'])

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    prompt = (
        "ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æŠœç²‹ã‚’å‚ç…§ã—ã¦è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
        + "\n\n".join(contexts)
        + f"\n\nè³ªå•: {question}"
    )
    resp = Groclient.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model="llama-3.3-70b-versatile",
    )
    answer = resp.choices[0].message.content.strip()
    await interaction.followup.send(f"**Q:** {question}\n**A:** {answer}")
@tree.command(name="image", description="ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")
async def upload_image(interaction: discord.Interaction):
    if not interaction.message.attachments:
        await interaction.response.send_message("ç”»åƒãŒæ·»ä»˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", ephemeral=True)
        return

    att = interaction.message.attachments[0]
    data = await att.read()
    image_url = att.url

    # ç”»åƒã‚’Groqã«é€ä¿¡
    resp = Groclient.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ã“ã®ç”»åƒã¯ä½•ã§ã™ã‹ï¼Ÿ"},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ],
        model="meta-llama/llama-4-scout-17b-16e-instruct",
        temperature=1,
        max_completion_tokens=1024,
        top_p=1,
        stream=False,
        stop=None,
    )
    answer = resp.choices[0].message.content.strip()
    await interaction.response.send_message(f"**å›ç­”:** {answer}")
@client.event
async def on_ready():
    await tree.sync()
    print(f"Logged in as {client.user}")

# Botèµ·å‹•
client.run(DISCORD_TOKEN)
